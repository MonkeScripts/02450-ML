{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the exercise, we will examine how to evaluate and compare classification methods.\n",
    "The tasks we will be concerned with solving is, firstly, how to determine a reasonable interval\n",
    "[θL, θU ] for the accuracy of a single classifier based on it’s prediction on a training set and\n",
    "secondly, how to compare two classifiers by estimating reasonable bounds for the difference of\n",
    "their accuracy θ = θA − θL.\n",
    "For simplicity, we will focus on comparing two k-nearest neighbor methods on the Iris dataset.\n",
    "Since this dataset consist of only N = 150 observations, we will use leave-one-out cross validation\n",
    "to construct the n = N model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection, tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Location of the iris.csv file: /home/monkescripts/anaconda3/lib/python3.12/site-packages/dtuimldmtools/data/iris.csv\n",
      "Ran 1.5.1 -- loaded the Iris data\n"
     ]
    }
   ],
   "source": [
    "# exercise 1.5.1\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris csv data using the Pandas library\n",
    "filename = importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/iris.csv\")\n",
    "\n",
    "# Print the location of the iris.csv file on your computer.\n",
    "# You should inspect it manually to understand the format and content\n",
    "print(\"\\nLocation of the iris.csv file: {}\".format(filename))\n",
    "\n",
    "# Load the iris.csv file using pandas\n",
    "# Note you do not need to undersatnd the details of the panda package\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Pandas returns a dataframe, (df) which could be used for handling the data.\n",
    "# We will however convert the dataframe to numpy arrays for this course as\n",
    "# is also described in the table in the exercise\n",
    "raw_data = df.values\n",
    "\n",
    "# Notice that raw_data both contains the information we want to store in an array\n",
    "# X (the sepal and petal dimensions) and the information that we wish to store\n",
    "# in y (the class labels, that is the iris species).\n",
    "\n",
    "# We start by making the data matrix X by indexing into data.\n",
    "# We know that the attributes are stored in the four columns from inspecting\n",
    "# the file.\n",
    "cols = range(0, 4)\n",
    "X = raw_data[:, cols]\n",
    "\n",
    "# We can extract the attribute names that came from the header of the csv\n",
    "attributeNames = np.asarray(df.columns[cols])\n",
    "\n",
    "# Before we can store the class index, we need to convert the strings that\n",
    "# specify the class of a given object to a numerical value. We start by\n",
    "# extracting the strings for each sample from the raw data loaded from the csv:\n",
    "classLabels = raw_data[:, -1]  # -1 takes the last column\n",
    "# Then determine which classes are in the data by finding the set of\n",
    "# unique class labels\n",
    "classNames = np.unique(classLabels)\n",
    "\n",
    "# We can assign each type of Iris class with a number by making a\n",
    "# Python dictionary as so:\n",
    "\n",
    "classDict = dict(zip(classNames, range(len(classNames))))\n",
    "\n",
    "# The function zip simply \"zips\" togetter the classNames with an integer,\n",
    "# like a zipper on a jacket.\n",
    "# For instance, you could zip a list ['A', 'B', 'C'] with ['D', 'E', 'F'] to\n",
    "# get the pairs ('A','D'), ('B', 'E'), and ('C', 'F').\n",
    "# A Python dictionary is a data object that stores pairs of a key with a value.\n",
    "# This means that when you call a dictionary with a given key, you\n",
    "# get the stored corresponding value. Try highlighting classDict and press F9.\n",
    "# You'll see that the first (key, value)-pair is ('Iris-setosa', 0).\n",
    "# If you look up in the dictionary classDict with the value 'Iris-setosa',\n",
    "# you will get the value 0. Try it with classDict['Iris-setosa']\n",
    "\n",
    "# With the dictionary, we can look up each data objects class label (the string)\n",
    "# in the dictionary, and determine which numerical value that object is\n",
    "# assigned. This is the class index vector y:\n",
    "\n",
    "y = np.array([classDict[cl] for cl in classLabels])\n",
    "\n",
    "# In the above, we have used the concept of \"list comprehension\", which\n",
    "# is a compact way of performing some operations on a list or array.\n",
    "# You could read the line  \"For each class label (cl) in the array of\n",
    "# class labels (classLabels), use the class label (cl) as the key and look up\n",
    "# in the class dictionary (classDict). Store the result for each class label\n",
    "# as an element in a list (because of the brackets []). Finally, convert the\n",
    "# list to a numpy array\".\n",
    "# Try running this to get a feel for the operation:\n",
    "# list = [0,1,2]\n",
    "# new_list = [element+10 for element in list]\n",
    "\n",
    "# We can determine the number of data objects and number of attributes using\n",
    "# the shape of X\n",
    "N, M = X.shape\n",
    "\n",
    "# Finally, the last variable that we need to have the dataset in the\n",
    "# \"standard representation\" for the course, is the number of classes, C:\n",
    "C = len(classNames)\n",
    "\n",
    "print(\"Ran 1.5.1 -- loaded the Iris data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation fold: 1/150\n",
      "Crossvalidation fold: 2/150\n",
      "Crossvalidation fold: 3/150\n",
      "Crossvalidation fold: 4/150\n",
      "Crossvalidation fold: 5/150\n",
      "Crossvalidation fold: 6/150\n",
      "Crossvalidation fold: 7/150\n",
      "Crossvalidation fold: 8/150\n",
      "Crossvalidation fold: 9/150\n",
      "Crossvalidation fold: 10/150\n",
      "Crossvalidation fold: 11/150\n",
      "Crossvalidation fold: 12/150\n",
      "Crossvalidation fold: 13/150\n",
      "Crossvalidation fold: 14/150\n",
      "Crossvalidation fold: 15/150\n",
      "Crossvalidation fold: 16/150\n",
      "Crossvalidation fold: 17/150\n",
      "Crossvalidation fold: 18/150\n",
      "Crossvalidation fold: 19/150\n",
      "Crossvalidation fold: 20/150\n",
      "Crossvalidation fold: 21/150\n",
      "Crossvalidation fold: 22/150\n",
      "Crossvalidation fold: 23/150\n",
      "Crossvalidation fold: 24/150\n",
      "Crossvalidation fold: 25/150\n",
      "Crossvalidation fold: 26/150\n",
      "Crossvalidation fold: 27/150\n",
      "Crossvalidation fold: 28/150\n",
      "Crossvalidation fold: 29/150\n",
      "Crossvalidation fold: 30/150\n",
      "Crossvalidation fold: 31/150\n",
      "Crossvalidation fold: 32/150\n",
      "Crossvalidation fold: 33/150\n",
      "Crossvalidation fold: 34/150\n",
      "Crossvalidation fold: 35/150\n",
      "Crossvalidation fold: 36/150\n",
      "Crossvalidation fold: 37/150\n",
      "Crossvalidation fold: 38/150\n",
      "Crossvalidation fold: 39/150\n",
      "Crossvalidation fold: 40/150\n",
      "Crossvalidation fold: 41/150\n",
      "Crossvalidation fold: 42/150\n",
      "Crossvalidation fold: 43/150\n",
      "Crossvalidation fold: 44/150\n",
      "Crossvalidation fold: 45/150\n",
      "Crossvalidation fold: 46/150\n",
      "Crossvalidation fold: 47/150\n",
      "Crossvalidation fold: 48/150\n",
      "Crossvalidation fold: 49/150\n",
      "Crossvalidation fold: 50/150\n",
      "Crossvalidation fold: 51/150\n",
      "Crossvalidation fold: 52/150\n",
      "Crossvalidation fold: 53/150\n",
      "Crossvalidation fold: 54/150\n",
      "Crossvalidation fold: 55/150\n",
      "Crossvalidation fold: 56/150\n",
      "Crossvalidation fold: 57/150\n",
      "Crossvalidation fold: 58/150\n",
      "Crossvalidation fold: 59/150\n",
      "Crossvalidation fold: 60/150\n",
      "Crossvalidation fold: 61/150\n",
      "Crossvalidation fold: 62/150\n",
      "Crossvalidation fold: 63/150\n",
      "Crossvalidation fold: 64/150\n",
      "Crossvalidation fold: 65/150\n",
      "Crossvalidation fold: 66/150\n",
      "Crossvalidation fold: 67/150\n",
      "Crossvalidation fold: 68/150\n",
      "Crossvalidation fold: 69/150\n",
      "Crossvalidation fold: 70/150\n",
      "Crossvalidation fold: 71/150\n",
      "Crossvalidation fold: 72/150\n",
      "Crossvalidation fold: 73/150\n",
      "Crossvalidation fold: 74/150\n",
      "Crossvalidation fold: 75/150\n",
      "Crossvalidation fold: 76/150\n",
      "Crossvalidation fold: 77/150\n",
      "Crossvalidation fold: 78/150\n",
      "Crossvalidation fold: 79/150\n",
      "Crossvalidation fold: 80/150\n",
      "Crossvalidation fold: 81/150\n",
      "Crossvalidation fold: 82/150\n",
      "Crossvalidation fold: 83/150\n",
      "Crossvalidation fold: 84/150\n",
      "Crossvalidation fold: 85/150\n",
      "Crossvalidation fold: 86/150\n",
      "Crossvalidation fold: 87/150\n",
      "Crossvalidation fold: 88/150\n",
      "Crossvalidation fold: 89/150\n",
      "Crossvalidation fold: 90/150\n",
      "Crossvalidation fold: 91/150\n",
      "Crossvalidation fold: 92/150\n",
      "Crossvalidation fold: 93/150\n",
      "Crossvalidation fold: 94/150\n",
      "Crossvalidation fold: 95/150\n",
      "Crossvalidation fold: 96/150\n",
      "Crossvalidation fold: 97/150\n",
      "Crossvalidation fold: 98/150\n",
      "Crossvalidation fold: 99/150\n",
      "Crossvalidation fold: 100/150\n",
      "Crossvalidation fold: 101/150\n",
      "Crossvalidation fold: 102/150\n",
      "Crossvalidation fold: 103/150\n",
      "Crossvalidation fold: 104/150\n",
      "Crossvalidation fold: 105/150\n",
      "Crossvalidation fold: 106/150\n",
      "Crossvalidation fold: 107/150\n",
      "Crossvalidation fold: 108/150\n",
      "Crossvalidation fold: 109/150\n",
      "Crossvalidation fold: 110/150\n",
      "Crossvalidation fold: 111/150\n",
      "Crossvalidation fold: 112/150\n",
      "Crossvalidation fold: 113/150\n",
      "Crossvalidation fold: 114/150\n",
      "Crossvalidation fold: 115/150\n",
      "Crossvalidation fold: 116/150\n",
      "Crossvalidation fold: 117/150\n",
      "Crossvalidation fold: 118/150\n",
      "Crossvalidation fold: 119/150\n",
      "Crossvalidation fold: 120/150\n",
      "Crossvalidation fold: 121/150\n",
      "Crossvalidation fold: 122/150\n",
      "Crossvalidation fold: 123/150\n",
      "Crossvalidation fold: 124/150\n",
      "Crossvalidation fold: 125/150\n",
      "Crossvalidation fold: 126/150\n",
      "Crossvalidation fold: 127/150\n",
      "Crossvalidation fold: 128/150\n",
      "Crossvalidation fold: 129/150\n",
      "Crossvalidation fold: 130/150\n",
      "Crossvalidation fold: 131/150\n",
      "Crossvalidation fold: 132/150\n",
      "Crossvalidation fold: 133/150\n",
      "Crossvalidation fold: 134/150\n",
      "Crossvalidation fold: 135/150\n",
      "Crossvalidation fold: 136/150\n",
      "Crossvalidation fold: 137/150\n",
      "Crossvalidation fold: 138/150\n",
      "Crossvalidation fold: 139/150\n",
      "Crossvalidation fold: 140/150\n",
      "Crossvalidation fold: 141/150\n",
      "Crossvalidation fold: 142/150\n",
      "Crossvalidation fold: 143/150\n",
      "Crossvalidation fold: 144/150\n",
      "Crossvalidation fold: 145/150\n",
      "Crossvalidation fold: 146/150\n",
      "Crossvalidation fold: 147/150\n",
      "Crossvalidation fold: 148/150\n",
      "Crossvalidation fold: 149/150\n",
      "Crossvalidation fold: 150/150\n"
     ]
    }
   ],
   "source": [
    "# This script crates predictions from three KNN classifiers using cross-validation\n",
    "\n",
    "# Maximum number of neighbors\n",
    "L = [1, 20, 80]\n",
    "\n",
    "CV = model_selection.LeaveOneOut()\n",
    "i = 0\n",
    "\n",
    "# store predictions.\n",
    "yhat = []\n",
    "y_true = []\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    print(\"Crossvalidation fold: {0}/{1}\".format(i + 1, N))\n",
    "\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # Fit classifier and classify the test points (consider 1 to 40 neighbors)\n",
    "    dy = []\n",
    "    for l in L:\n",
    "        knclassifier = KNeighborsClassifier(n_neighbors=l)\n",
    "        knclassifier.fit(X_train, y_train)\n",
    "        y_est = knclassifier.predict(X_test)\n",
    "\n",
    "        dy.append(y_est)\n",
    "        # errors[i,l-1] = np.sum(y_est[0]!=y_test[0])\n",
    "    depth = 10\n",
    "    dtc = tree.DecisionTreeClassifier(criterion=\"gini\", max_depth=depth)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_est = dtc.predict(X_test)\n",
    "    dy.append(y_est)\n",
    "    dy = np.stack(dy, axis=1)\n",
    "    yhat.append(dy)\n",
    "    y_true.append(y_test)\n",
    "    i += 1\n",
    "\n",
    "yhat = np.concatenate(yhat)\n",
    "y_true = np.concatenate(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 1th classifier 0.96\n",
      "Accuracy of 2th classifier 0.98\n",
      "Accuracy of 3th classifier 0.88\n",
      "Accuracy of 4th classifier 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "for i in range(yhat.shape[1]):\n",
    "    y_pred = yhat[:, i]\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy of {i+1}th classifier {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeffrey interval\n",
    "![jeffrey](images/jeffrey.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier0, Theta point estimate {0.956953642384106}  CI:  {(0.9194225123023887, 0.9831344032786383)}\n",
      "Classifier1, Theta point estimate {0.9768211920529801}  CI:  {(0.947595470192869, 0.9943357273513206)}\n",
      "Classifier2, Theta point estimate {0.8774834437086093}  CI:  {(0.8208649682806228, 0.9246522400250042)}\n",
      "Classifier3, Theta point estimate {0.9437086092715232}  CI:  {(0.901897648320583, 0.9744661594031807)}\n"
     ]
    }
   ],
   "source": [
    "from dtuimldmtools import jeffrey_interval\n",
    "\n",
    "# Compute the Jeffreys interval\n",
    "alpha = 0.05\n",
    "thetahatA, CIA = zip(\n",
    "    *[jeffrey_interval(y_true, yhat[:, i], alpha=alpha) for i in range(yhat.shape[1])]\n",
    ")  \n",
    "# Assume probability distribution follows beta\n",
    "# Theta point estimate: mean probability\n",
    "# CI: Confidence interval\n",
    "for i in range(yhat.shape[1]):\n",
    "    print(f\"Classifier{i}, Theta point estimate\", {thetahatA[i]}, \" CI: \", {CIA[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier0, Theta point estimate {0.956953642384106}  CI:  {(0.9268651478327419, 0.9801903026556568)}\n",
      "Classifier1, Theta point estimate {0.9768211920529801}  CI:  {(0.9538135438545823, 0.9927410729129449)}\n",
      "Classifier2, Theta point estimate {0.8774834437086093}  CI:  {(0.8310541533673992, 0.9182188891809034)}\n",
      "Classifier3, Theta point estimate {0.9437086092715232}  CI:  {(0.9099669242182495, 0.9707822989147973)}\n"
     ]
    }
   ],
   "source": [
    "from dtuimldmtools import jeffrey_interval\n",
    "\n",
    "# Compute the Jeffreys interval\n",
    "alpha = 0.1\n",
    "thetahatA, CIA = zip(\n",
    "    *[jeffrey_interval(y_true, yhat[:, i], alpha=alpha) for i in range(yhat.shape[1])]\n",
    ")\n",
    "# Assume probability distribution follows beta\n",
    "# Theta point estimate: mean probability\n",
    "# CI: Confidence interval\n",
    "for i in range(yhat.shape[1]):\n",
    "    print(f\"Classifier{i}, Theta point estimate\", {thetahatA[i]}, \" CI: \", {CIA[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jeffreyalpha](images/jeffreyalpha.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mcnemar's test\n",
    "![mcneymar](images/mcneymar'stest.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of McNemars test using alpha= 0.05\n",
      "Comparison matrix n\n",
      "[[143.   1.]\n",
      " [  4.   2.]]\n",
      "Warning, n12+n21 is low: n12+n21= 5.0\n",
      "Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (-0.0489356618488046, 0.008952198322319305)\n",
      "p-value for two-sided test A and B have same accuracy (exact binomial test): p= 0.375\n",
      "theta = theta_A-theta_B point estimate -0.02  CI:  (-0.0489356618488046, 0.008952198322319305) p-value 0.375\n"
     ]
    }
   ],
   "source": [
    "from dtuimldmtools import mcnemar\n",
    "\n",
    "# Compute the Jeffreys interval\n",
    "alpha = 0.05\n",
    "[thetahat, CI, p] = mcnemar(y_true, yhat[:, 0], yhat[:, 1], alpha=alpha)\n",
    "\n",
    "print(\"theta = theta_A-theta_B point estimate\", thetahat, \" CI: \", CI, \"p-value\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![neymar'sinterpretation](images/neymar'sinterpretation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MB having a relatively higher accuracy than MA. Meanwhile, the p-value is relatively high,\n",
    "indicating the result is likely due to chance. All in all the result is inconclusive and we should\n",
    "not conclude MB is better than MA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s we saw in 7.1.1, there is a relatively higher difference in performance between MA and\n",
    "MC , which is confirmed by McNemar’s test. The performance difference θ is estimated to be\n",
    "between (approximately) 0.05 and 0.1. The confidence interval is therefore well clear of 0 and\n",
    "the low p-value (p < 0.01) indicates the result is not likely to be due to chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of McNemars test using alpha= 0.05\n",
      "Comparison matrix n\n",
      "[[140.   4.]\n",
      " [  2.   4.]]\n",
      "Warning, n12+n21 is low: n12+n21= 6.0\n",
      "Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (-0.018500516252076715, 0.045153854891712086)\n",
      "p-value for two-sided test A and B have same accuracy (exact binomial test): p= 0.6875\n",
      "theta = theta_A-theta_B point estimate 0.013333333333333334  CI:  (-0.018500516252076715, 0.045153854891712086) p-value 0.6875\n"
     ]
    }
   ],
   "source": [
    "from dtuimldmtools import mcnemar\n",
    "\n",
    "# Compute the mcneymar between KNN (nearest neighbour=1 and decision tree)\n",
    "alpha = 0.05\n",
    "[thetahat, CI, p] = mcnemar(y_true, yhat[:, 0], yhat[:, -1], alpha=alpha)\n",
    "\n",
    "print(\"theta = theta_A-theta_B point estimate\", thetahat, \" CI: \", CI, \"p-value\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical evaluation of a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from: /home/monkescripts/Documents/NUS/exchange/02450 ML/week7\n",
      "Ran Exercise 5.1.5 - loading the Wine data\n"
     ]
    }
   ],
   "source": [
    "# exercise 5.1.5\n",
    "import os\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load Matlab data file and extract variables of interest\n",
    "filename = importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/wine.mat\")\n",
    "workingDir = os.getcwd()\n",
    "print(\"Running from: \" + workingDir)\n",
    "\n",
    "# Pick the relevant variables\n",
    "mat_data = loadmat(filename)\n",
    "X = mat_data[\"X\"]\n",
    "y = mat_data[\"y\"].astype(int).squeeze()\n",
    "C = mat_data[\"C\"][0, 0]\n",
    "M = mat_data[\"M\"][0, 0]\n",
    "N = mat_data[\"N\"][0, 0]\n",
    "\n",
    "attributeNames = [i[0][0] for i in mat_data[\"attributeNames\"]]\n",
    "classNames = [j[0] for i in mat_data[\"classNames\"] for j in i]\n",
    "\n",
    "# Remove outliers\n",
    "outlier_mask = (X[:, 1] > 20) | (X[:, 7] > 10) | (X[:, 10] > 200)\n",
    "valid_mask = np.logical_not(outlier_mask)\n",
    "X = X[valid_mask, :]\n",
    "y = y[valid_mask]\n",
    "# Remove attribute 12 (Quality score)\n",
    "X = X[:, 0:11]\n",
    "attributeNames = attributeNames[0:11]\n",
    "# Update N and M\n",
    "N, M = X.shape\n",
    "\n",
    "print(\"Ran Exercise 5.1.5 - loading the Wine data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([-0.10686908]), array([-0.01804807])), array([0.00587949]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.stats as st\n",
    "import sklearn.tree\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "X, y = X[:, :10], X[:, 10:]\n",
    "# This script crates predictions from three KNN classifiers using cross-validation\n",
    "\n",
    "test_proportion = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=test_proportion\n",
    ")\n",
    "\n",
    "mA = sklearn.linear_model.LinearRegression().fit(X_train, y_train)\n",
    "mB = sklearn.tree.DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "yhatA = mA.predict(X_test)\n",
    "yhatB = mB.predict(X_test)[:, np.newaxis]  #  justsklearnthings\n",
    "\n",
    "# perform statistical comparison of the models\n",
    "# compute z with squared error.\n",
    "zA = np.abs(y_test - yhatA) ** 2\n",
    "\n",
    "# compute confidence interval of model A\n",
    "alpha = 0.05\n",
    "CIA = st.t.interval(\n",
    "    1 - alpha, df=len(zA) - 1, loc=np.mean(zA), scale=st.sem(zA)\n",
    ")  # Confidence interval\n",
    "\n",
    "# Compute confidence interval of z = zA-zB and p-value of Null hypothesis\n",
    "zB = np.abs(y_test - yhatB) ** 2\n",
    "z = zA - zB\n",
    "CI = st.t.interval(\n",
    "    1 - alpha, len(z) - 1, loc=np.mean(z), scale=st.sem(z)\n",
    ")  # Confidence interval\n",
    "p = 2 * st.t.cdf(-np.abs(np.mean(z)) / st.sem(z), df=len(z) - 1)  # p-value\n",
    "CI, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using kfold instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from: /home/monkescripts/Documents/NUS/exchange/02450 ML/week7\n",
      "Ran Exercise 5.1.5 - loading the Wine data\n"
     ]
    }
   ],
   "source": [
    "# exercise 5.1.5\n",
    "import os\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load Matlab data file and extract variables of interest\n",
    "filename = importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/wine.mat\")\n",
    "workingDir = os.getcwd()\n",
    "print(\"Running from: \" + workingDir)\n",
    "\n",
    "# Pick the relevant variables\n",
    "mat_data = loadmat(filename)\n",
    "X = mat_data[\"X\"]\n",
    "y = mat_data[\"y\"].astype(int).squeeze()\n",
    "C = mat_data[\"C\"][0, 0]\n",
    "M = mat_data[\"M\"][0, 0]\n",
    "N = mat_data[\"N\"][0, 0]\n",
    "\n",
    "attributeNames = [i[0][0] for i in mat_data[\"attributeNames\"]]\n",
    "classNames = [j[0] for i in mat_data[\"classNames\"] for j in i]\n",
    "\n",
    "# Remove outliers\n",
    "outlier_mask = (X[:, 1] > 20) | (X[:, 7] > 10) | (X[:, 10] > 200)\n",
    "valid_mask = np.logical_not(outlier_mask)\n",
    "X = X[valid_mask, :]\n",
    "y = y[valid_mask]\n",
    "# Remove attribute 12 (Quality score)\n",
    "X = X[:, 0:11]\n",
    "attributeNames = attributeNames[0:11]\n",
    "# Update N and M\n",
    "N, M = X.shape\n",
    "\n",
    "print(\"Ran Exercise 5.1.5 - loading the Wine data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' on line 29 (1569560374.py, line 89)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[121], line 89\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(\"Ran Exercise 5.1.5 - loading the Wine data\")lity score)\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '[' on line 29\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.stats as st\n",
    "import sklearn.tree\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "X, y = X[:, :10], X[:, 10:]\n",
    "# This script crates predictions from three KNN classifiers using cross-validation\n",
    "K = 5  # exercise 5.1.5\n",
    "import os\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load Matlab data file and extract variables of interest\n",
    "filename = importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/wine.mat\")\n",
    "workingDir = os.getcwd()\n",
    "print(\"Running from: \" + workingDir)\n",
    "\n",
    "# Pick the relevant variables\n",
    "mat_data = loadmat(filename)\n",
    "X = mat_data[\"X\"]\n",
    "y = mat_data[\"y\"].astype(int).squeeze()\n",
    "C = mat_data[\"C\"][0, 0]\n",
    "M = mat_data[\"M\"][0, 0]\n",
    "N = mat_data[\"N\"][0, 0]\n",
    "\n",
    "attributeNames = [i[0][0] # exercise 5.1.5\n",
    "import os\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load Matlab data file and extract variables of interest\n",
    "filename = importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/wine.mat\")\n",
    "workingDir = os.getcwd()\n",
    "print(\"Running from: \" + workingDir)\n",
    "\n",
    "# Pick the relevant variables\n",
    "mat_data = loadmat(filename)\n",
    "X = mat_data[\"X\"]\n",
    "y = mat_data[\"y\"].astype(int).squeeze()\n",
    "C = mat_data[\"C\"][0, 0]\n",
    "M = mat_data[\"M\"][0, 0]\n",
    "N = mat_data[\"N\"][0, 0]\n",
    "\n",
    "attributeNames = [i[0][0] for i in mat_data[\"attributeNames\"]]\n",
    "classNames = [j[0] for i in mat_data[\"classNames\"] for j in i]\n",
    "\n",
    "# Remove outliers\n",
    "outlier_mask = (X[:, 1] > 20) | (X[:, 7] > 10) | (X[:, 10] > 200)\n",
    "valid_mask = np.logical_not(outlier_mask)\n",
    "X = X[valid_mask, :]\n",
    "y = y[valid_mask]\n",
    "# Remove attribute 12 (Qua# exercise 5.1.5\n",
    "import os\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load Matlab data file and extract variables of interest\n",
    "filename = importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/wine.mat\")\n",
    "workingDir = os.getcwd()\n",
    "print(\"Running from: \" + workingDir)\n",
    "\n",
    "# Pick the relevant variables\n",
    "mat_data = loadmat(filename)\n",
    "X = mat_data[\"X\"]\n",
    "y = mat_data[\"y\"].astype(int).squeeze()\n",
    "C = mat_data[\"C\"][0, 0]\n",
    "M = mat_data[\"M\"][0, 0]\n",
    "N = mat_data[\"N\"][0, 0]\n",
    "\n",
    "attributeNames = [i[0][0] for i in mat_data[\"attributeNames\"]]\n",
    "classNames = [j[0] for i in mat_data[\"classNames\"] for j in i]\n",
    "\n",
    "# Remove outliers\n",
    "outlier_mask = (X[:, 1] > 20) | (X[:, 7] > 10) | (X[:, 10] > 200)\n",
    "valid_mask = np.logical_not(outlier_mask)\n",
    "X = X[valid_mask, :]\n",
    "y = y[valid_mask]\n",
    "# Remove attribute 12 (Quality score)\n",
    "X = X[:, 0:11]\n",
    "attributeNames = attributeNames[0:11]\n",
    "# Update N and M\n",
    "N, M = X.shape\n",
    "\n",
    "print(\"Ran Exercise 5.1.5 - loading the Wine data\")lity score)\n",
    "X = X[:, 0:11]\n",
    "attributeNames = attributeNames[0:11]\n",
    "# Update N and M\n",
    "N, M = X.shape\n",
    "\n",
    "print(\"Ran Exercise 5.1.5 - loading the Wine data\")for i in mat_data[\"attributeNames\"]]\n",
    "classNames = [j[0] for i in mat_data[\"classNames\"] for j in i]\n",
    "\n",
    "# Remove outliers\n",
    "outlier_mask = (X[:, 1] > 20) | (X[:, 7] > 10) | (X[:, 10] > 200)\n",
    "valid_mask = np.logical_not(outlier_mask)\n",
    "X = X[valid_mask, :]\n",
    "y = y[valid_mask]\n",
    "# Remove attribute 12 (Quality score)\n",
    "X = X[:, 0:11]\n",
    "attributeNames = attributeNames[0:11]\n",
    "# Update N and M\n",
    "N, M = X.shape\n",
    "\n",
    "print(\"Ran Exercise 5.1.5 - loading the Wine data\")\n",
    "CV = model_selection.KFold(n_splits=K, shuffle=True)\n",
    "count = 1\n",
    "for train_index, test_index in CV.split(X):\n",
    "\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "    mA = sklearn.linear_model.LinearRegression().fit(X_train, y_train)\n",
    "    mB = sklearn.tree.DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "    yhatA = mA.predict(X_test)\n",
    "    yhatB = mB.predict(X_test)[:, np.newaxis]  #  justsklearnthings\n",
    "\n",
    "    # perform statistical comparison of the models\n",
    "    # compute z with squared error.\n",
    "    zA = np.abs(y_test - yhatA) ** 2\n",
    "\n",
    "    # compute confidence interval of model A\n",
    "    alpha = 0.05\n",
    "    CIA = st.t.interval(\n",
    "        1 - alpha, df=len(zA) - 1, loc=np.mean(zA), scale=st.sem(zA)\n",
    "    )  # Confidence interval\n",
    "\n",
    "    # Compute confidence interval of z = zA-zB and p-value of Null hypothesis\n",
    "    zB = np.abs(y_test - yhatB) ** 2\n",
    "    z = zA - zB\n",
    "    CI = st.t.interval(\n",
    "        1 - alpha, len(z) - 1, loc=np.mean(z), scale=st.sem(z)\n",
    "    )  # Confidence interval\n",
    "    p = 2 * st.t.cdf(-np.abs(np.mean(z)) / st.sem(z), df=len(z) - 1)  # p-value\n",
    "    print(f\"fold{count} Interval: {CI} p: {p}\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Changes in Confidence Interval:\n",
    "\n",
    "Hold-out: The confidence interval is based on a single train-test split, so it may be less reliable.\n",
    "\n",
    "K-Fold Cross-Validation: The confidence interval is based on multiple splits, so it is expected to be narrower and more reliable.\n",
    "\n",
    "Leave-One-Out Cross-Validation (LOO): The confidence interval will be even narrower but computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from: /home/monkescripts/Documents/NUS/exchange/02450 ML/week7\n",
      "Ran Exercise 5.1.5 - loading the Wine data\n"
     ]
    }
   ],
   "source": [
    "# exercise 5.1.5\n",
    "import os\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load Matlab data file and extract variables of interest\n",
    "filename = importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/wine.mat\")\n",
    "workingDir = os.getcwd()\n",
    "print(\"Running from: \" + workingDir)\n",
    "\n",
    "# Pick the relevant variables\n",
    "mat_data = loadmat(filename)\n",
    "X = mat_data[\"X\"]\n",
    "y = mat_data[\"y\"].astype(int).squeeze()\n",
    "C = mat_data[\"C\"][0, 0]\n",
    "M = mat_data[\"M\"][0, 0]\n",
    "N = mat_data[\"N\"][0, 0]\n",
    "\n",
    "attributeNames = [i[0][0] for i in mat_data[\"attributeNames\"]]\n",
    "classNames = [j[0] for i in mat_data[\"classNames\"] for j in i]\n",
    "\n",
    "# Remove outliers\n",
    "outlier_mask = (X[:, 1] > 20) | (X[:, 7] > 10) | (X[:, 10] > 200)\n",
    "valid_mask = np.logical_not(outlier_mask)\n",
    "X = X[valid_mask, :]\n",
    "y = y[valid_mask]\n",
    "# Remove attribute 12 (Quality score)\n",
    "X = X[:, 0:11]\n",
    "attributeNames = attributeNames[0:11]\n",
    "# Update N and M\n",
    "N, M = X.shape\n",
    "\n",
    "print(\"Ran Exercise 5.1.5 - loading the Wine data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00019834453862457141, 1.8767632196090023e-65]\n",
      "(-0.2731773426596104, -0.12389255719527052) (-0.22112504712001307, -0.17598311294392016)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "import sklearn.linear_model\n",
    "import sklearn.tree\n",
    "\n",
    "# requires data from exercise 1.5.1\n",
    "from sklearn import model_selection\n",
    "\n",
    "from dtuimldmtools import *\n",
    "from dtuimldmtools.statistics.statistics import correlated_ttest\n",
    "\n",
    "loss = 2\n",
    "X, y = X[:, :10], X[:, 10:]\n",
    "# This script crates predictions from three KNN classifiers using cross-validation\n",
    "\n",
    "K = 10  # We presently set J=K\n",
    "m = 1\n",
    "r = []\n",
    "kf = model_selection.KFold(n_splits=K)\n",
    "\n",
    "for dm in range(m):\n",
    "    y_true = []\n",
    "    yhat = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, y_train = X[train_index, :], y[train_index]\n",
    "        X_test, y_test = X[test_index, :], y[test_index]\n",
    "\n",
    "        mA = sklearn.linear_model.LinearRegression().fit(X_train, y_train)\n",
    "        mB = sklearn.tree.DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "        yhatA = mA.predict(X_test)\n",
    "        yhatB = mB.predict(X_test)[:, np.newaxis]  # justsklearnthings\n",
    "        y_true.append(y_test)\n",
    "        yhat.append(np.concatenate([yhatA, yhatB], axis=1))\n",
    "\n",
    "        r.append(\n",
    "            np.mean(np.abs(yhatA - y_test) ** loss - np.abs(yhatB - y_test) ** loss)\n",
    "        )\n",
    "\n",
    "# Initialize parameters and run test appropriate for setup II\n",
    "alpha = 0.05\n",
    "rho = 1 / K\n",
    "p_setupII, CI_setupII = correlated_ttest(r, rho, alpha=alpha)\n",
    "\n",
    "if m == 1:\n",
    "    y_true = np.concatenate(y_true)[:, 0]\n",
    "    yhat = np.concatenate(yhat)\n",
    "\n",
    "    # note our usual setup I ttest only makes sense if m=1.\n",
    "    zA = np.abs(y_true - yhat[:, 0]) ** loss\n",
    "    zB = np.abs(y_true - yhat[:, 1]) ** loss\n",
    "    z = zA - zB\n",
    "\n",
    "    CI_setupI = st.t.interval(\n",
    "        1 - alpha, len(z) - 1, loc=np.mean(z), scale=st.sem(z)\n",
    "    )  # Confidence interval\n",
    "    p_setupI = st.t.cdf(-np.abs(np.mean(z)) / st.sem(z), df=len(z) - 1)  # p-value\n",
    "\n",
    "    print([p_setupII, p_setupI])\n",
    "    print(CI_setupII, CI_setupI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 7.4.3\n",
    "import importlib_resources\n",
    "import numpy as np\n",
    "\n",
    "# Load list of names from files\n",
    "\n",
    "fmale = open(importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/male.txt\"), \"r\")\n",
    "ffemale = open(\n",
    "    importlib_resources.files(\"dtuimldmtools\").joinpath(\"data/female.txt\"), \"r\"\n",
    ")\n",
    "mnames = fmale.readlines()\n",
    "fnames = ffemale.readlines()\n",
    "names = mnames + fnames\n",
    "gender = [0] * len(mnames) + [1] * len(fnames)\n",
    "fmale.close()\n",
    "ffemale.close()\n",
    "\n",
    "# Extract X, y and the rest of variables. Include only names of >4 characters.\n",
    "X = np.zeros((len(names), 4))\n",
    "y = np.zeros((len(names), 1))\n",
    "n = 0\n",
    "for i in range(0, len(names)):\n",
    "    name = names[i].strip().lower()\n",
    "    if len(name) > 3:\n",
    "        X[n, :] = [\n",
    "            ord(name[0]) - ord(\"a\") + 1,\n",
    "            ord(name[1]) - ord(\"a\") + 1,\n",
    "            ord(name[-2]) - ord(\"a\") + 1,\n",
    "            ord(name[-1]) - ord(\"a\") + 1,\n",
    "        ]\n",
    "        y[n, 0] = gender[i]\n",
    "        n += 1\n",
    "X = X[0:n, :]\n",
    "y = y[0:n, :]\n",
    "\n",
    "N, M = X.shape\n",
    "C = 2\n",
    "attributeNames = [\"1st letter\", \"2nd letter\", \"Next-to-last letter\", \"Last letter\"]\n",
    "classNames = [\"Female\", \"Male\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a uniform prior, assuming male and female names are\n",
    "equally likely (i.e. P (y = 0) = P (y = 1) = 0.5). Compute the classification error\n",
    "\n",
    "Alternative: Use empirical, Probability based on proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 6.503836188463763%\n"
     ]
    }
   ],
   "source": [
    "# exercise 7.4.4\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "np.random.seed(2450)\n",
    "y = y.squeeze()\n",
    "0\n",
    "# Naive Bayes classifier parameters\n",
    "alpha = 1.0  # pseudo-count, additive parameter (Laplace correction if 1.0 or Lidtstone smoothing otherwise)\n",
    "fit_prior = True  # uniform prior (change to True to estimate prior from data)\n",
    "\n",
    "# K-fold crossvalidation\n",
    "K = 10\n",
    "CV = model_selection.KFold(n_splits=K, shuffle=True)\n",
    "\n",
    "X = X[:, 0:4]  # using all 4 letters,\n",
    "# for using e.g. only third letter or first and last try X[:,[2]] and X[:, [0,3]]\n",
    "\n",
    "# We need to specify that the data is categorical.\n",
    "# MultinomialNB does not have this functionality, but we can achieve similar\n",
    "# results by doing a one-hot-encoding - the intermediate steps in in training\n",
    "# the classifier are off, but the final result is corrent.\n",
    "# If we didn't do the converstion MultinomialNB assumes that the numbers are\n",
    "# e.g. discrete counts of tokens. Without the encoding, the value 26 wouldn't\n",
    "# mean \"the token 'z'\", but it would mean 26 counts of some token,\n",
    "# resulting in 1 and 2 meaning a difference in one count of a given token as\n",
    "# opposed to the desired 'a' versus 'b'.\n",
    "X = OneHotEncoder().fit_transform(X=X)\n",
    "\n",
    "errors = np.zeros(K)\n",
    "k = 0\n",
    "for train_index, test_index in CV.split(X):\n",
    "    # print('Crossvalidation fold: {0}/{1}'.format(k+1,K))\n",
    "\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    nb_classifier = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    y_est_prob = nb_classifier.predict_proba(X_test)\n",
    "    y_est = np.argmax(y_est_prob, 1)\n",
    "\n",
    "    errors[k] = np.sum(y_est != y_test, dtype=float) / y_test.shape[0]\n",
    "    k += 1\n",
    "\n",
    "# Plot the classification error rate\n",
    "print(\"Error rate: {0}%\".format(100 * np.mean(errors)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
